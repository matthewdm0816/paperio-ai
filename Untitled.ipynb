{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import paperio.match_core_ as core\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from DQN_sample import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(num_episodes):\n",
    "    # reinitialize fields\n",
    "    core.init_field(51, 101, 3000, 0xFFFF)\n",
    "    player_funcs = [PlayerFunc(play=target_net_wrapper(i)) for i in (0, 1)]\n",
    "\n",
    "    # state = get_screen(1)\n",
    "\n",
    "    result = core.parse_match(player_funcs)\n",
    "    logs = core.LOG_PUBLIC # records each frame in 0th player's view.\n",
    "    history_len = len(logs)\n",
    "    print(result, logs)\n",
    "\n",
    "    for i_frame in range(history_len):\n",
    "        if i_frame % 2 == 0: # only process those of first agent.\n",
    "            state, action = logs[i_frame].unsqueeze(0), core.OPS[i_frame]\n",
    "            try:\n",
    "                next_state = logs[i_frame + 2].unsqueeze(0)\n",
    "                done = False\n",
    "            except:\n",
    "                next_state = None\n",
    "                done = True\n",
    "            if action == 'L':\n",
    "                action = torch.tensor([[0.]], device=device)\n",
    "            elif action == 'R':\n",
    "                action = torch.tensor([[2.]], device=device)\n",
    "            else:\n",
    "                action = torch.tensor([[1.]], device=device)\n",
    "\n",
    "            reward = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "\n",
    "            if i_frame == history_len - 1: # killed opp\n",
    "                reward = 3\n",
    "            elif i_frame == history_len - 2: # killed by opp\n",
    "                reward = -3\n",
    "            else:\n",
    "                reward = simple_reward(state)\n",
    "\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            optimize_model()\n",
    "\n",
    "    episode_durations.append(logs[-1].eq(1).sum())\n",
    "    plot_durations()\n",
    "\n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "# env.render()\n",
    "# env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = DQN()\n",
    "states = torch.zeros((128,1,102,101),dtype=torch.float32).random_(0, 1024) / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 102, 101])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([s for s in states if s is not None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 102, 101])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[torch.tensor([_ % 2 == 0 for _ in range(128)])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[None] = 0\n",
    "states[No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
